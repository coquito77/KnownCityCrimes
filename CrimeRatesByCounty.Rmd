---
title: "Crime Rates By County"
author: "Moises Evangelista"
date: "January 19, 2016"
output:
  pdf_document:
    fig_width: 7
    fig_height: 9
    fig_caption: true
    fig_crop: false
fontsize: 11pt
header-includes:
- \usepackage{palatino}
- \renewcommand{\familydefault}{\sfdefault} % sans serif
- \fontfamily{ppl}\selectfont
---

This report uses data from the FBI UCR tables to get known crimes rates by year for different cities in California. The goal is to determine crime rate changes for California counties before and after AB109 was implemented.sa

Data sources:

1.[City crimes rates from FIB table 8](http://www.fbi.gov/about-us/cjis/ucr/crime-in-the-u.s/)

2.[City of California shapefile](http://www.dot.ca.gov/hq/tsip/gis/datalibrary/Metadata/cities.html)

3.[Counties shape file from U.S. Census](https://www.census.gov/geo/maps-data/data/cbf/cbf_counties.html)

\vspace{5mm}

The FBI data has the following disclaimer:

Caution against ranking
Figures used in this Report were submitted voluntarily by law enforcement agencies throughout the country. Individuals using these tabulations are cautioned against drawing conclusions by making direct comparisons between cities. Comparisons lead to simplistic and/or incomplete analyses that often create misleading perceptions adversely affecting communities and their residents. Valid assessments are possible only with careful study and analysis of the range of unique conditions affecting each local law enforcement jurisdiction. It is important to remember that crime is a social problem and, therefore, a concern of the entire community. In addition, the efforts of law enforcement are limited to factors within its control. The data user is, therefore, cautioned against comparing statistical data of individual agencies. Further information on this topic can be obtained in Uniform Crime Reporting Statistics:  Their Proper Use.

In other words, comparing cities among other cities is not a good idea, but comparing a city within itself by year is OK.

\newpage

```{r echo=FALSE, message=FALSE, include=FALSE}

rm(list = ls(all = TRUE)) #start with empty workspace

startTime <- Sys.time()

# set global chunk options

knitr::opts_chunk$set(cache = TRUE, echo = FALSE, include = FALSE)

doInstall <- FALSE # Change to TRUE if you do want packages installed.
toInstall <- c("knitr", "rvest", "NbClust", "cluster", "foreign", "tidyverse", 
               "scales", "RCurl", "RODBC", "xtable","data.table",
               "benford.analysis", "strucchange", "forecast",
               "RColorBrewer","rgeos","maptools","mapproj")

if(doInstall){install.packages(toInstall, repos = "http://cran.us.r-project.org")}
lapply(toInstall, library, character.only = TRUE)

setwd("~/GitHub/KnownCityCrimes/") # set the working directory
list.files() # see whats there

```



```{r downloadDataSimplier, echo=FALSE, include=FALSE, eval=TRUE}

# Download FBI Data

theurlPart1 <- "http://www.fbi.gov/about-us/cjis/ucr/crime-in-the-u.s/"

theURLPart2_2015 <- "2015/crime-in-the-u.s.-2015/tables/table-8/table-8-state-pieces"
theURLPart3_2015 <- "/table_8_offenses_known_to_law_enforcement_california_by_city_2015.xls"

theURLPart2_2014 <- "2014/crime-in-the-u.s.-2014/tables/table-8/table-8-by-state/"
theURLPart3_2014 <- "Table_8_Offenses_Known_to_Law_Enforcement_by_California_by_City_2014.xls"

theURLPart2_2013 <- "2013/crime-in-the-u.s.-2013/tables/table-8/table-8-state-cuts/"
theURLPart3_2013 <- "table_8_offenses_known_to_law_enforcement_california_by_city_2013.xls"

theURLPart2_2012 <- "2012/crime-in-the-u.s.-2012/tables/8tabledatadecpdf/"
theURLPart3_2012 <- "table-8-state-cuts/table_8_offenses_known_to_law_enforcement_by_california_by_city_2012.xls"

theURLPart2_2011 <- "2011/crime-in-the-u.s.-2011/tables/table8statecuts/"
theURLPart3_2011 <- "table_8_offenses_known_to_law_enforcement_california_by_city_2011.xls"

theURLPart2_2010 <- "2010/crime-in-the-u.s.-2010/tables/table-8/10tbl08ca.xls"

theurl2009 <- "http://www2.fbi.gov/ucr/cius2009/data/table_08_ca.html"

table8ColNamesCurrent <- c("City","Population","Violent crime",
                           "Murder and nonnegligent manslaughter","Rape (revised definition)1",
                           "Rape (legacy definition)2","Robbery","Aggravated assault",
                           "Property crime","Burglary","Larceny- theft",
                           "Motor vehicle theft","Arson")

table8ColNames <- c("City","Population","Violent crime",
                           "Murder and nonnegligent manslaughter",
                           "Rape (legacy definition)2","Robbery",
                           "Aggravated assault","Property crime",
                           "Burglary","Larceny- theft","Motor vehicle theft",
                           "Arson")

content2011 <- read_html(paste0(theurlPart1,theURLPart2_2011,theURLPart3_2011)) %>%
  html_table(fill = TRUE) %>%
  .[[2]] %>% 
  mutate(year = "CA2011",
         `Rape (revised definition)1` = "")

names(content2011) <- c(table8ColNames,"year","Rape (revised definition)1")

content2010 <- read_html(paste0(theurlPart1,theURLPart2_2010)) %>%
  html_table(fill = TRUE) %>%
  .[[2]] %>% 
  mutate(year = "CA2010",
         `Rape (revised definition)1` = "")

names(content2010) <- c(table8ColNames,"year","Rape (revised definition)1")

content2009 <- read_html(theurl2009) %>%
  html_table(fill = TRUE) %>%
  .[[1]] %>% 
  mutate(year = "CA2009",
         `Rape (revised definition)1` = "")

names(content2009) <- c(table8ColNames,"year","Rape (revised definition)1")

Years <- seq(2012, 2015, by = 1) %>% as.vector()

all_tables <- vector("list", length = (length(Years)))

# use algorithm to import data by year
 
for(i in 1:length(Years)){
  
  year <- Years[i]
  
  part2 <- paste0("theURLPart2_", year)
  
  part2 <- get(part2)
  part3 <- paste0("theURLPart3_", year)
  
  part3 <- get(part3)
  
  link <- paste0(theurlPart1,part2,part3)
  
  print(link)

  if (year == 2012) {
    
    x <- read_html(link) %>%
      html_table(fill = TRUE) %>%
      .[[2]]
    
    names(x) <- table8ColNames
    x <- x %>% 
      mutate(`Rape (revised definition)1` = "") %>% 
      as.data.frame()
  }  else if (year == 2013) {
    
    x <- read_html(link) %>%
      html_table(fill = TRUE) %>%
      .[[2]]
    
    names(x) <- table8ColNamesCurrent
    x <- x %>% as.data.frame
    
   } else
      x <- read_html(link) %>%
      html_table(fill = TRUE) %>%
      .[[1]] 
    
    names(x) <- table8ColNamesCurrent
  
  all_tables[[i]]   <- x  %>% 
    mutate(year = paste0("CA",year))
  
}

datacombo <- all_tables %>% # head(1000) %>%
  plyr::ldply(data.frame) %>% 
  select(-c(`Rape..revised.definition.1`))

names(datacombo) <- gsub("[^[:alnum:]]", "", names(datacombo))

datacombo2 <- rbind(content2009,content2010,content2011) %>% 
  select(-`Rape (revised definition)1`)

names(datacombo2) <- gsub("[^[:alnum:]]", "", names(datacombo2))

rm(list = setdiff(ls(), c("datacombo","datacombo2")))

comboRecs <- rbind(datacombo2,datacombo)

# make number into correct format

comboRecs <- comboRecs %>%
  mutate_at(vars(Population:Arson),
            funs(as.numeric(gsub(",","",.)))) %>%
  mutate_at(vars(Violentcrime:Arson), funs(rate = (./Population)*100000)) %>% 
  mutate(City =  gsub("[[:digit:]]", "", City),
         City =  gsub("Carmel", "Carmel-by-the-Sea", City),
         City =  gsub("Rancho Santa Margarit", "Rancho Santa Margarita", City),
         City =  gsub("Rancho Santa Margaritaa", "Rancho Santa Margarita", City),
         City =  gsub("City of Angels", "Angels Camp", City))

# clean up the work space
# 
rm(list=ls(pattern="^data"))

```




```{r processShapeFiles, eval = FALSE}

# rm(list = ls(all = TRUE)) #start with empty workspace

# city shape file 
# Calif Cities
# http://www.dot.ca.gov/hq/tsip/gis/datalibrary/Metadata/cities.html

temp <- tempfile()

download.file("http://www.dot.ca.gov/hq/tsip/gis/datalibrary/zip/Boundaries/Cities2015.zip",
               quiet = TRUE, 
              destfile = temp)

con <- unzip(temp)

# take a look at the files on the data
con

# US Counties

download.file('http://www2.census.gov/geo/tiger/GENZ2016/shp/cb_2016_us_county_500k.zip', 'county.zip',
              quiet = TRUE)

temp <- unzip('county.zip')

## 
## process maps

# rm(list = ls(all = TRUE)) #start with empty workspace

# rgdal::readOGR() works almost the same, but you need to strip the '.shp' from the end of the filenames:


library(rgdal)

ogrDrivers()
dsn <- getwd()
ogrListLayers(dsn)
ogrInfo(dsn)

shps <- dir(getwd(),full.names = TRUE, "*.shp$")
 
#shps <- Filter(function(x) grepl("CalWorks_Approved\\.", x), shps)
 
shpsNames <- sub('\\.shp$',"",shps) %>% basename(.)
 
for (i in 1:length(shps)) {
  
  x <- rgdal::readOGR(dsn = shps[i], layer = shpsNames[i])
  
  # x <- rgdal::readOGR(dsn = "~/GitHub/KnownCityCrimes/cb_2016_us_county_500k.shp", layer = "cb_2016_us_county_500k");
  xdata <- x@data
  
  x1 <- rgeos::gSimplify(x, tol = 1/1000, topologyPreserve=TRUE)
  
  x1 <- rgeos::gBuffer(x1, byid=TRUE, width=0)
  
  # do some staff with "poly_df" that doesn't support SpatialPolygonsDataFrame
  # then convert it to SPDF back again
  x1 <- SpatialPolygonsDataFrame(x1, xdata)
  # add new column to SPDF:
  # 
  # x2 <- x
  # 
  #cleanedMap2 <- broom::tidy(x1, region = "DIST")
  # 
  # cleanedMap <- broom::tidy(x, region = "DIST")
  # 
  # x <- dplyr::left_join(cleanedMap,
  #                       #xdata,
  #                       x@data,
  #                       by = c("id" = "DIST")) %>%
  #   mutate(type = shpsNames[i],
  #          type = gsub("_" ," ", type))
  # 
  # x <- data.frame(x)
  
    # x2 <- dplyr::left_join(cleanedMap2,
    #                     xdata,
    #                     #x@data,
    #                     by = c("id" = "NAME")) %>%
    # mutate(type = shpsNames[i],
    #        type = gsub("_" ," ", type))
    # 
 # x <- data.frame(x2)
 
  assign(shpsNames[i],x)
  
  #rm(x)
  
  #rm(cleanedMap)
}


CaCounties <-  subset(cb_2016_us_county_500k,
                      STATEFP == "06")

##  clip the cities that are not withing the county layer

head(Cities2015@data)

cityData <- Cities2015@data %>% rownames_to_column( var = "NewID1")

Cities2015@data$id <- rownames(Cities2015@data)

califCitiesInter <- gIntersection(Cities2015, CaCounties, 
                                  byid = TRUE,
                                  drop_lower_td = TRUE)

#califCitiesInter <-  SpatialPolygonsDataFrame(califCitiesInter, cityData)

# simplify the maps and make them data frames

frtfCaCounties <-  CaCounties %>%  
  broom::tidy( region = "NAME")

frtfCitiesInterset <- califCitiesInter %>% 
  broom::tidy( region = "NAME") %>% 
  separate(id, into = c("NewID1", "NewID2"), sep = " ") %>% 
  left_join(cityData, 
            by = c('NewID1')) %>% 
  rename(City = NAME)

# get city centroids for city labels on map

centroids.df <- as.data.frame(coordinates(Cities2015)) %>% 
  select(Longitude = 1, Latitude = 2)

pop.df <- data.frame(id = rownames(Cities2015@data),
                     Names = Cities2015@data$NAME,
                     centroids.df)

#  Cities2015@data$id <- rownames(Cities2015@data)

califCitiesWithLabels <- left_join(frtfCitiesInterset, pop.df,
                                   by = c("NewID1" = "id"))  %>%
  select(Names, Longitude, Latitude, NewID1, County) %>%
  distinct()

## remove unnecessary files and save data

keepers <- c("CrimeRatesByCounty.pdf","CrimeRatesByCounty.Rmd",
             "global.R","LICENSE","README.md","server.R","ui.R","data") #list.files()[26:32]

NotKeepers <- setdiff(list.files(),keepers)

do.call(file.remove,list(NotKeepers))

rm(list=setdiff(ls(), c("comboRecs", "califCitiesWithLabels",
                        "frtfCitiesInterset","frtfCaCounties",
                        "centroids.df","califCitiesWithLabels")))

save.image(file="data.RData")

```


```{r processData, eval = TRUE}
# rm(list = ls(all = TRUE)); setwd("~/GitHub/KnownCityCrimes/"); list.files() 

load("data.RData")

ggplot() +
  geom_polygon(data = frtfCitiesInterset, aes(long, 
                               lat, 
                               group = group),
               fill = "grey40",
               colour = "blue",
               alpha = .7,
               size = .05) +
  geom_polygon(data = frtfCaCounties, aes(long,
                                          lat,
                                          group = group), 
               fill = "khaki",
               color = "red",
               alpha = .2,
               size = 0.1) +
  coord_map() +
  theme_minimal() +
  geom_text(data = califCitiesWithLabels %>% filter(Names %in% c("Los Angeles",
                                       "Riverside",
                                       "San Diego")) , 
            aes(label = Names, x = Longitude, y = Latitude),
            color = "red",
            check_overlap = TRUE,
            size = 1)

# merge map data with set from table8 crimes

head(frtfCitiesInterset)

frtfCitiesInterset <- frtfCitiesInterset %>% setDT(key = 'City')

comboRecs <- comboRecs %>% setDT(key = 'City')

startTime <- Sys.time()

comboCities <- merge(frtfCitiesInterset, comboRecs,
                      by.x = c('City'), by.y = c('City'), all.x = TRUE,
                      allow.cartesian = TRUE)

Sys.time() - startTime

# take a look at those cities not on the map layer

anti_join(frtfCitiesInterset,
          comboRecs,
          by = c('City' = 'City')) %>%
  select(County, City) %>%
  distinct()

anti_join(comboRecs,
          frtfCitiesInterset,
          by = c('City' = 'City')) %>%
  select(City) %>%
  distinct()

# get the limits for each county

longLimits <- frtfCaCounties %>%
  group_by(id) %>%
  select(long, id) %>%
  unique() %>%
  arrange(long) %>%  ## optional
  filter(long %in% range(long)) %>%
   mutate(Number = 1,
          cumsum = cumsum(Number)) %>%
  select(long, id, cumsum) %>%
  mutate(cumsum = ifelse(cumsum == 1, 
                         "longMax", "LongMin")) %>%
  spread(cumsum, long)

latLimits <- frtfCaCounties %>%
  group_by(id) %>%
  select(lat, id) %>%
  unique() %>%
  arrange(lat) %>%  ## optional
  filter(lat %in% range(lat)) %>%
   mutate(Number = 1,
          cumsum = cumsum(Number)) %>%
  select(lat, id, cumsum) %>%
  mutate(cumsum = ifelse(cumsum == 1, 
                         "latMax", "LatMin")) %>%
  spread(cumsum, lat)

# centroids.df <- as.data.frame(coordinates(comboCities))
# names(centroids.df) <- c("Longitude", "Latitude") 

comboCities %>%
  filter(County == "Los Angeles") %>% 
  filter(City != 'Vernon' &
           City !='Industry') %>%
  # select(NAME) %>%
  # distinct() %>% arrange((NAME))
  ggplot( ) +
  geom_polygon(aes(long, lat, group = group, fill = Violentcrime_rate),
               # fill="grey40",
               colour = "grey90",
               alpha = .7,
               size = .05) +
  geom_text(data = califCitiesWithLabels,
            aes(label = Names, x = Longitude, y = Latitude), size = 1) +
  scale_fill_gradientn(name = "Rate",
                       colours = rainbow(7),
                       limits = c(0,2000)) +
  geom_polygon(data = frtfCaCounties, aes(long,
                                          lat,
                                          group = group), 
               fill = "khaki",
               color = "red",
               alpha = .2,
               size = 0.1) +
  coord_map() +
  theme_minimal() + 
  facet_wrap(~ year)

```

```{r createbenfordAnalysis, eval=TRUE, include=FALSE}

benfordAnalysis <- comboCities %>%
  select(City, County, Year = year,
         Murderandnonnegligentmanslaughter:Aggravatedassault,
         Burglary:Arson) %>%
  distinct() %>%
  gather(Metric, Count, -c(City, County, Year)) # %>% filter(Year == "CA2014")

cp <- benford(benfordAnalysis$Count, 2, sign = "both")
# cp #prints
# plot(cp) #plots

head(suspectsTable(cp), 10) #prints the digits by decreasing order of discrepancies
#gets observations of the 2 most suspicious groups
suspects <- getSuspects(cp, benfordAnalysis, how.many = 2) %>%
  na.omit()

nrow(suspects)/nrow(benfordAnalysis)
```
```{r createbenfordAnalysis3, eval=FALSE, include=FALSE}

benfordAnalysisPop <- comboCities %>%
  select(City, County, Year = year,
         Pop2010) %>%
  # mutate(Pop2010 = as.numeric(Pop2010)) %>%
  distinct() %>%
  gather(Metric, Count, -c(City, County, Year)) # %>% filter(Year == "CA2014")

cp <- benford(benfordAnalysisPop$Count, 2, sign = "both")
cp #prints
plot(cp) #plots

head(suspectsTable(cp), 10) #prints the digits by decreasing order of discrepancies
#gets observations of the 2 most suspicious groups
suspectsPop <- getSuspects(cp, benfordAnalysisPop, how.many = 2) %>%
  na.omit()

# percent of pop counts not deviating from bedfords law

nrow(suspectsPop)/nrow(benfordAnalysis)

```


```{r getCrimeMax, eval = TRUE}

RateLimits <- comboCities %>%
  select(County, ends_with("rate")) %>%
  gather(Crime, Value, -c(County)) %>% unique() %>% # head(500) %>%
  group_by(County, Crime) %>%
  # mutate(MaxRate = max(Value, na.rm = TRUE)) %>%
  summarise(Avg = mean(Value, na.rm = TRUE),
            StndDvtn = sd(Value, na.rm = TRUE), 
            MaxRate = max(Value, na.rm = TRUE),
            iqr = IQR(Value, na.rm = TRUE),
            Median = median(Value, na.rm = TRUE)) %>%
  mutate( tst = (iqr*3) + Median,
          CrimLimit =  ifelse( MaxRate > 3000, tst, MaxRate)) %>%
  select(County, Crime, CrimLimit) %>% unique()

ggplot(RateLimits, aes(CrimLimit, County)) +
  geom_point() +
  scale_x_continuous(labels = comma) +
  facet_wrap(~Crime, ncol = 2, scales = "free")

```

```{r exportTheData, eval=TRUE}

# export the data

dir.create("./data", showWarnings = FALSE)

frtfCitiesInterset %>%
  select(long, lat, City, County, group) %>%
  fwrite(file = "./data/frtfCitiesInterset.txt", 
              sep = "\t", na = "0")

comboRecs %>%
  select(City, year,
         ends_with("rate")) %>%
  fwrite(file = "./data/comboRecs.txt", 
              sep = "\t", na = "0")

frtfCaCounties %>%
  select(long, lat, id, group) %>%
  fwrite(file = "./data/frtfCaCounties.txt", 
         sep = "\t", na = "0")

left_join(longLimits, latLimits) %>%
  fwrite( file = "./data/countyLimits.txt", 
          sep = "\t", na = "0")

suspects %>%
  fwrite(file = "./data/suspects.txt",
         sep = "\t", na = "0")

califCitiesWithLabels %>%
  fwrite(file = "./data/califCitiesWithLabels.txt",
         sep = "\t", na = "0")

RateLimits %>%
  fwrite(file = "./data/RateLimits.txt",
         sep = "\t", na = "0")

```

```{r plotCityRatesbyYear, eval=TRUE, include=TRUE, fig.cap= "The cities of Vernon and Industry have extreme violent crimes rates because they have few residents compared to most cities", message = FALSE, warning = FALSE, include=TRUE} 

colourCount = length(unique(comboCities$year))
getPalette = colorRampPalette(brewer.pal(8, "Accent"))

comboCities %>%
  select(Violentcrime_rate, City, year, County) %>% 
  filter(County == "Los Angeles") %>%
  distinct() %>% 
  ggplot(aes(Violentcrime_rate, City)) +
  geom_point(aes(colour = factor(year),
                 shape = factor(year))) +
  scale_x_continuous(trans = log_trans(),
                     breaks = c(100,1000,10000,
                                50000),
                     labels = comma_format()) +
  scale_shape_manual(name = "Violent crime \nrate per year",
                     values = c(0:6)) +
  scale_color_manual(values = getPalette(colourCount),
                     name = "Violent crime \nrate per year",
                     guide = guide_legend(keywidth = .5,
                                          keyheight = .5,
                                          direction = "vertical",
                                          title.position = "left",
                                          label.position = "right", 
                                          label.hjust = 0, 
                                          label.vjust = 0, 
                                          ncol = 3, 
                                          byrow = TRUE,
                                          title.theme = element_text(size = 5, 
                                                                     colour = "black", 
                                                                     angle = 00),
                                          label.theme = element_text(size = 6, 
                                                                     colour = "black", 
                                                                     angle = 00))) +
  theme_minimal() +
  xlab("Crime Rate per 100,000 residents (log scale)") +
  ylab("City") +
  theme(axis.text.x  = element_text(angle = 00,
                                    vjust = 0.5, size = 8), 
        axis.text.y  = element_text(angle = 0,
                                    vjust = 0.5, size = 8),
        legend.position = "top") +
  guides(colour = guide_legend(override.aes = list(alpha = 1)))

```

```{r MapCitiesViolentCrime, fig.height=10, eval=TRUE, include=TRUE, fig.cap= "The city of Compton has one of the highest violent crimes rates in the county for the year 2014", message = FALSE, warning = FALSE, include=TRUE} 

setCities <- comboCities %>%
  select(long, lat, City, County, year, group, 
  ends_with("Rate")) %>%
  filter( County == "Los Angeles", year == "CA2014") %>%
  as.data.frame()

countyLimitsFiltered <- left_join(longLimits, latLimits) %>%
  filter( id == "Los Angeles")

CrimeLimits <- RateLimits %>% 
  filter( County == "Los Angeles",
                      Crime == "Violentcrime_rate") %>%
  ungroup() %>%
  select(CrimLimit)

CrimeLimits <- CrimeLimits$CrimLimit

califCitiesWithLabelsFiltered <- califCitiesWithLabels %>%
  filter(County == "Los Angeles") %>%
  group_by(Names, County) %>% 
 distinct()

longMax <- countyLimitsFiltered$longMax*-1
LongMin <- countyLimitsFiltered$LongMin*-1
latMax <- countyLimitsFiltered$latMax
LatMin <- countyLimitsFiltered$LatMin

setCities %>% left_join(califCitiesWithLabelsFiltered, 
                        c("City" = "Names")) %>%
  droplevels() %>%
  ggplot(aes(long, lat, group = group, fill = Violentcrime_rate)) +
  geom_polygon(aes(),
               # fill="grey40",
               colour = "grey90",
               alpha = .7,
               size = .05) +
  scale_fill_gradientn(name = "Violent crime Rate per \n100,000 residents in 2014",
                       colours = rainbow(7),
                       limits = c(0, CrimeLimits) ) +
  geom_text(aes(label = City, x = Longitude, y = Latitude),
            check_overlap = TRUE,
            size = 2) +
  geom_polygon(data = frtfCaCounties, aes(long,
                                          lat,
                                          group = group),
               fill = "khaki",
               color = "red",
               alpha = .2,
               size = 0.1)  +
  coord_map(xlim = -c(longMax, LongMin), 
            ylim = c(latMax, LatMin)) +
  theme_minimal() +
  theme(legend.position = c(.15, .45),
        #plot.margin = unit(c(0,0,-.5,-.5), "cm"),
        axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank())

```

```{r echo=FALSE}

# TODO
# create bendford analysis -- done
# add city labels to the map -- done
# add zoom feature to map
# add segment that compares crime rate changes since 2011
# add good limits for map fill colors -- done
# add links to data souces and code -- done
# simplyfy maps done
# use fread data and fwrite data to write csv files
# shift islands in LA county up
# make maps using leaf see  and 
# https://r-spatial.github.io/mapview/articles/articles/mapview_05-extras.html
# 

```


